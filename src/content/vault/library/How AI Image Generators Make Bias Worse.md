---
title: How AI Image Generators Make Bias Worse
kind: articles
url: https://www.lis.ac.uk/stories/how-ai-image-generators-make-bias-worse
publisher: lis.ac.uk
peer:
  - "[[AI|AI ethics]]"
---

- ## Extracts
- "Take the example of gender disparity when it comes to generating an image of a Fortune 500 CEO. What should a fair gender split look like?
  Should it accurately reflect the current statistics which are roughly 9 to 1? In one sense, this can be seen as a fair representation of reality. But others might see this as unfair for perpetuating unequal and unjust power structures and for discouraging women from applying for C-suite roles.
  Perhaps a distribution should be a 50/50 split. this would achieve demographic parity as it matches the gender split of the population.
  We could consider applying this across all jobs and roles, but this assumes that there are no intrinsic differences between genders. Would it be fair to depict prisoners at a 50/50 split, for example, when men currently make up 93% of the global prison population?
  Perhaps the only fair distribution is to make the output completely random. But even then, 

 - "defining the gender category with a binary value has already introduced bias into the system."