---
title: AI
editUrl: false
aliases:
  - ai
  - artificial intelligence
  - machine learning
  - chatbots
  - genAI
  - generative AI
  - AI ethics
  - ML
parent:
  - "[[tech]]"
  - "[[ethical tech and tech for ethics]]"
  - "[[techno-politics]]"
peer:
  - "[[internet]]"
  - "[[new media]]"
  - "[[exploring ideas]]"
  - "[[experimental tech]]"
tags:
  - tool
  - ethical-issue
---

I actively avoid engaging in this discourse for the most part. I got in as early as possible, tried to press for literally any ethical consideration and got quickly jaded. Then the industry boomed and I'm sick of talking about it. I believe for the most part that analytical AI is useful and generative AI is harmful. There are a few exceptions of genuinely interesting projects or important queries. There is a lot of AI slop and AI harm. I dissuade casual, uncritical use of these black-box systems and avoid it wherever possible, though this is increasingly difficult in knowledge-work, online-work and tech-work. I probably don't want to talk about it, engage with it or use it myself - what we focus on is important and there are so many more important priorities.

### disambiguation

* analytical AI - machine learning that is genuinely useful, specifically trained models for eg analysing medical data for patterns of development of cancers. more likely to have ethical considerations embedded from the beginning, deeply embedded in STEM research
* generative AI - more contentious, links to [worker's rights](/mdx/earth/workers-rights), [art making](/mdx/earth/creative-process), etc
* LLMs - large language models, as above
* ML - machine learning, general methods or specific purpose

### misc notes

* better lockdown needed for replicative use cases eg voice training for those losing their voice, need more stringent security/local only and strict usage control, and policy on impersonators
* I don't believe in sentiment analysis with ML because sentiment is so context-specific and text is limited in form compared to verbal/bodily/tone and also sentiment can differ interpersonally and is so relational that the intended audience changes the sentiment too much that analysis by way of third-party is already difficult let alone third-party that is non-human and inherently out of context - there is never enough context to extrapolate from and even one person's sentiment could differ over the space of one conversation, too variable to guess at
* shouldn't be asking ai for resource curation - not neutral, how they're encoded varies, favours dominant narratives, doesn't uncover rich multi-modal pluriversal knowledge
* ai generated children's books, articles, videos etc exist now. AI generated SHIRTS even
* A primary use of general purpose llm is for general casual science/scientific communication but that is such a dangerous thing to rely on for science for a layperson!
* uses of LLMs I am yet to find fault with or better alternative for (an ever-shrinking list)
  * understanding uses of metaphors, idioms, contextual jokes
  * 'tip-of-your-tongue' word-finding
  * simplifying legalese or legal procedure
* to come: 'you don't need an LLM for that'
* * on ai power draw and computational power, how can we conceptualise specific models for specific purpose on local sites/as personal portables, with direct, viewable tangible power draw and data draw and prompt answering all entirely self-contained

- A primary use of general purpose GPT is for general casual science/scientific communication but that is such a dangerous thing to rely on for science for a layperson!
